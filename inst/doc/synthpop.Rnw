%\documentclass[article]{jss}
\documentclass[nojss]{jss}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Beata Nowok\\University of Edinburgh \And 
        Gillian M Raab\\University of Edinburgh  \And 
        Chris Dibben\\University of Edinburgh}
\title{synthpop : Bespoke creation of synthetic data in \proglang{R}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Beata Nowok, Gillian M Raab, Chris Dibben} %% comma-separated
\Plaintitle{Bespoke creation of synthetic data in R} %% without formatting
\Shorttitle{\pkg{synthpop}: Synthetic Population} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
In many contexts, confidentiality constraints severely restrict access to unique and valuable microdata. Synthetic data which mimics the real data and preserves the relationships between variables but do not contain any disclosive records is one possible solution to this problem. The \pkg{synthpop} package, introduced in this paper, provides routines to generate a synthetic version of real data sets. We describe the methodology and its consequences for the data characteristics. We illustrate the package features using a real data example.
}
\Keywords{ synthetic data, disclosure control, CART, \proglang{R}}
\Plainkeywords{synthetic data, disclosure control, CART, R} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Beata Nowok\\
  Institute of Geography\\
  School of GeoSciences\\
  University of Edinburgh\\
  Drummond Street\\
  Edinburgh EH8 9XP\\
  E-mail: \email{beata.nowok@ed.ac.uk}}
%% URL: \url{http:/}}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851


%% need no \usepackage{Sweave.sty}

% \VignetteIndexEntry{Using synthpop}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

<<echo=false>>=
options(width=77,digits=4,useFancyQuotes=FALSE)
@



%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section[Intro]{Introduction and background}
\label{sec:intro}
\subsection{Synthetic data for disclosure control}
National statistical agencies and other institutions gather large amounts of information about individuals and organisations. Such data can be used to understand population processes so as to inform policy and planning. The cost of such data can be considerable, both for the collectors and the subjects who provide their data. Because of confidentiality constraints and guarantees issued to data subjects the full access to such data is often restricted to the staff of the collection agencies. Traditionally, data collectors have used anonymization along with simple perturbation methods such as aggregation, recoding, record-swapping, suppression of sensitive values or adding random noise to prevent the identification of data subjects. Advances in computer technology have shown that such measures may not prevent disclosure {\cite{Ohm_2010} and in addition they may compromise the conclusions one can draw from such data (\cite{elliot_purdam_2007}, \cite{Winkler_2007}).

In response to these limitations there have been several initiatives, most of them centred around the U.S. Census Bureau, to generate synthetic data which can be released to users outside the setting where the original data are held. The basic idea of the synthetic data is to replace some or all of the real values by sampling from appropriate probability distributions so that the essential statistical features of the original data are preserved. The monograph by \cite{Drechsler_book} summarises some of the theoretical and policy developments. The approach has been developed along similar lines to recent practical experience with multiple imputation methods. The data collection agency generates multiple synthetic data sets and inferences are obtained by combining the results of models fitted to each of them. The methods are detailed in \cite{RRR_2003} and have been further discussed and exemplified in a series of papers (\cite{Reiter_2010}, \cite{Reiter_RSS}, \cite{reiter_cart}, \cite{Caiola_and_R_2010} and \cite{DR_jasa_2010} among others). 

The original aim of these methods have been to provide publicly available data sets that can be used for inference in place of the real data. However, such inferences will only be valid if the model used to construct the synthetic data is the true mechanism that has generated the real data. At best, this is an approximation and published results comparing estimates from real and synthetic data have been mixed. %%(add references) 

Our aim in writing the \pkg{synthpop} package is a more modest one of providing test data for users of confidential data sets. These test data should resemble the actual data as closely as possible, but would never be used in any final analyses. The users carry out exploratory analyses and test models on the synthetic data, but they, or perhaps staff of the data collection agencies, would use the code developed on the synthetic data to run their final analyses on the real data. This approach recognises the limitations of synthetic data produced by these methods. 
It is interesting to note that a similar approach is currently being used for both of the synthetic products made available by the U.S. Census Bureau\footnote{see \url{http://www.census.gov/programs-surveys/sipp/methodology/sipp-synthetic-beta-data-product.html} and \url{https://www.census.gov/ces/dataproducts/synlbd/}}, where results obtained from the synthetic data are validated on the real data (``gold standard files"). 

\subsection[Mot]{Motivation for the development of \pkg{synthpop}}
The England and Wales Longitudinal Study (ONS LS), the Scottish Longitudinal Study (SLS) and the Northern Ireland Longitudinal Study (NILS) are rich micro-datasets linking samples from the national Census in each country to administrative data (births, deaths, marriages, cancer registrations and other sources) for individuals and their immediate families across several decades. Whilst unique and valuable resources, the sensitive nature of the information they contain means that access to the microdata is restricted to approved researchers and longitudinal study (LS) support staff, who can only view and work with the data in safe settings controlled by the national statistical agencies. Consequently, compared to other census data products such as the aggregate statistics or samples of anonymised records, the three longitudinal studies (LSs) are used by a small number of researchers, a situation which limits their potential impact. Given that confidentiality constraints and legal restrictions mean that open access is not possible with the real microdata, alternative options are needed to allow academics and other users to carry out their research more freely. To address this the SYLLS (Synthetic Data Estimation for UK Longitudinal Studies) project\footnote{see \url{http://www.lscs.ac.uk/projects/synthetic-data-estimation-for-uk-longitudinal-
studies/}} has been funded by the Economic and Social Research Council to develop techniques to produce synthetic data which mimics the real data and preserves the relationships between variables and transitions of individuals over time, but can be made available to accredited researchers to analyse on their own computers. The \pkg{synthpop} package for \proglang{R} has been written as part of the SYLLS project to allow LS support staff to produce synthetic data for users of the LSs, that are tailored to the needs of each individual user.

We will use the term ``synthesiser" for someone who is producing the synthetic data from the real data and hence has access to both. The term ``analyst" will refer to someone who has no access to the real data and will be using the synthetic data for exploratory analyses. After the exploratory analysis the analyst will develop confirmatory models and can send the syntax to a synthesiser to carry out the gold standard analyses. 
As well as providing routines to generate the synthetic data the \pkg{synthpop} package contains routines that can be used by the analyst to summarise synthetic data and fitted models from synthetic data and those that can be used by the synthesiser to compare gold standard analyses with those from the synthetic data. Although primarily targeted to the data from the LSs, the package is written in a form that should make it applicable to other confidential data where the resource of synthetic data would be valuable.  It allows the user to extend the types of data that can be handled by writing their own routines that can be added to the package.
\subsection[papsum]{Structure of this paper}
The structure of this paper is as follows. The next section introduces the notation, terminology and the main theoretical results needed for the simplest and, we expect, the most common use of the package. More details of the theoretical results for the general case can be found in \cite{synthpop_RSS}. Readers not interested in the theoretical details can now proceed directly to Section~\ref{sec:synthpop} which presents the package and its basic functionality. Section~\ref{sec:examples} that follows provides some illustrative examples. The concluding Section~\ref{sec:conclusions} indicates directions for future developments.   

\section[notation]{Overview of method}
\label{sec:notation}
Real data from a survey or a sample from a census are available to the synthesiser. They consist of a sample of $n$ units consisting of $(x_{obs},y_{obs})$ where $x_{obs}$, which may be null, is a matrix of data that can be released unchanged to the analyst and $y_{obs}$ is an $n$ x $p$ matrix of $p$ variables that require to be synthesised.  We consider here the simple case when the synthetic data sets (syntheses) will each have the same number of records as the original data and the method of generating the synthetic sample (e.g. simple random sampling or a complex sample design) matches that of the real data.
\subsection{Generating synthetic data} 
The observed data are assumed to be a sample from a population with parameters that can be estimated by the synthesiser, specifically $y_{obs}$ is assumed to be a sample from $f(y|x_{obs},\theta)$ where $\theta$ is a vector of parameters. This could be a hypothetical infinite super-population or a finite population which is large enough for finite population corrections to be ignored. The synthesiser fits the data to the assumed distribution and obtains estimates of its parameters. In most implementations of synthetic data generation, including \pkg{synthpop}, the joint distribution is defined in terms of a series of conditional distributions. A column of $y_{obs}$ is selected and the distribution of this variable, conditional on $x_{obs}$ is estimated.  Then the next column is selected and its distribution is estimated conditional on $x_{obs}$ and the column of $y_{obs}$ already selected.  The distribution of subsequent columns of $y_{obs}$ are estimated conditional on $x_{obs}$ and all previous columns of $y_{obs}$.

The generation of the synthetic data sets can proceed in parallel to the fitting of each conditional distribution. Each column of the synthetic data is generated from the assumed distribution, conditional on $x_{obs}$, the fitted parameters of the conditional distribution (simple synthesis) and the synthesised values of all the previous columns of $y_{obs}$. Alternatively the synthetic values can be generated from the posterior distribution of the parameters (proper synthesis). In both cases, a total of $m$ synthetic data sets are generated. 
\subsection{Inference from the synthetic data}
If the analyst wants to estimate a model from the synthetic data, she will fit the model to each of the $m$ synthetic data sets and obtain an estimate of its vector of parameters $\beta$ from each synthetic data set as $(\hat{\beta_{1}},\cdots,\hat{\beta_{i}},\cdots, \hat{\beta_{m}})$. If the model for the data is correct the $m$ estimates from the synthetic data will be centred around the estimate $\hat{\beta}$ that would have been obtained from the observed data. We are assuming that it is the goal of the analyst to use the synthetic data to estimate $\hat{\beta}$ and its estimated variance-covariance matrix $V_{\hat{\beta}}$. The mean of $m$ synthetic estimates, $\bar{\hat{\beta}} =\sum{\hat{\beta_{i}}}/m$ provides an unbiased estimate of $\hat{\beta}$. Provided the observed and synthetic data are generated by the same sampling scheme then $V_{\bar{\hat{\beta}}} = \sum{V_{\hat{\beta_{i}}}}/m$ will be an unbiased estimate of $V_{\hat{\beta}}$. The variance-covariance matrix of $\bar{\hat{\beta}}$, conditional on $\hat{\beta}$ and $V_{\hat{\beta}}$ becomes  $V_{\hat{\beta}}/m$ which can be estimated from $V_{\bar{\hat{\beta}}}/m$. Thus the stochastic error in the mean of the synthetic estimates about the values from the observed data can be reduced to a negligible quantity by increasing $m$. It must be remembered, however that the unbiasedness of $\bar{\hat{\beta}}$  only applies when observed data are a sample from the distribution used for synthesis. In practical applications differences between the analyses on the observed data and those from the mean of the syntheses will be found because the data do not conform to the model used for synthesis. Such differences will not be reduced by increasing $m$. The synthesiser, with access to the observed data, can estimate $\bar{\hat{\beta}} - {\hat{\beta}}$ and compare it to its standard error in order to judge the extent that this model mismatch affects the estimates.

Note that this result is different from most %%those of ...,...,... and
 other papers %%. The other papers 
which aim to use the results of the synthetic data to make inference about the population from which the real gold standard data have been generated.  But our aim, in the simplest case we describe above, is only to make inferences to the results that would have been obtained by the gold standard analysis, with the expectation that the analyst will run final models on the real data. Also, unlike most of the literature above, in the simplest case we do not sample from the predictive distribution of the parameters to create the synthetic data but an option to do so is available in \pkg{synthpop}. This approach has been proposed recently by \cite{reiter_kinney_2012} for partially synthetic data. The justification for this approach for fully synthetic data is in \cite{synthpop_RSS} along with the details of how the \pkg{synthpop} package can be used to make inferences to the population.

\section{The synthpop package in practice}
\label{sec:synthpop}
\subsection{Obtaining the software}
The \pkg{synthpop} package is an add-on package to the statistical software \proglang{R}. It is freely available from the Comprehensive R Archive Network at \url{http://CRAN.R-project.org/package=synthpop}. It requires a non-standard package \pkg{party} (\cite{doi:10.1198/106186006X133933}) which needs to be installed prior to loading package \pkg{synthpop} from a library. The namespace of package \pkg{party} is loaded automatically when package \pkg{synthpop} is loaded. 

The \pkg{synthpop} package utilises the structure and some functions of the \pkg{mice} multiple imputation package (\cite{mice_jss_2011}) but adopts and extends it for the specific purpose of generating synthetic data. 

\subsection{Basic functionality}
\label{sec:basicfun}
The \pkg{synthpop} package aims to provide a user with an easy way of generating synthetic versions of real data sets. Via the function \code{syn()} a synthetic data set is produced using a single command. The only required argument is \code{data} which is a data frame or a matrix containing the data to be synthesised. By default, a single synthetic data set is produced using simple synthesis. Multiple data sets can be obtained by setting parameter \code{m} to a desired number and proper synthesis is conducted when argument \code{proper} is set to \code{TRUE}. Data synthesis can be further customized with other optional parameters. Below, we only present the salient features of the \code{syn()} function. See examples in Section~\ref{sec:examples} and the \proglang{R} documentation for the function \code{syn()} for more details (command \code{?syn} at the \proglang{R} console).\\


\textit{Choice of synthesising method} \\
The synthesising models are defined by a parameter \code{method} which can be a single string or a vector of strings. Providing a single method name assumes the same synthesising method for each variable, unless a variable's data type precludes it. Note that a variable to be synthesised first that has no predictors is a special case and its synthetic values are generated by random sampling with replacement from the original data (\code{"sample"} method). In general, a user can choose between parametric and non-parametric methods. The latter are based on classification and regression trees (CART) that can handle any type of data. By default the \code{ctree} implementation of the CART technique is used for all variables to be synthesised. Setting the parameter \code{method} to \code{"parametric"} assigns default parametric methods to variables to be synthesised based on their types. The default parametric methods for numeric, binary, unordered factor and ordered factor data type are specified in vector \code{defaultMethod} which may be customised if desired. Alternatively a method can be chosen out of the available methods for each variable separately. The methods currently implemented are listed in Table~\ref{tab:meth}. A new synthesising method can be easily introduced by writing a function named \code{syn.newmethod()} and then specifying \code{method} parameter of \code{syn()} function as \code{"newmethod"}.\\

\begin{table}[h]
\centering
\begin{tabular}{l l l}
\hline Method & Description & Data type   \\ 
\hline 
\noalign{\vskip 5pt}  
\textit{Non-parametric}  \\ 
 \code{ctree, cart} & Classification and regression trees & any \\ 
 \code{surv.ctree} & Classification and regression trees & duration \\ 
\noalign{\vskip 5pt} 
\textit{Parametric}\\ 
 \code{norm} & Normal linear regression  & numeric \\ 
 \code{normrank}* & Normal linear regression preserving & numeric \\ 
  & the marginal distribution  &  \\ 
 \code{logreg}*  & Logistic regression                    & binary \\ 
 \code{polyreg}* & Polytomous logistic regression         & factor, >2 levels\\ 
 \code{polr}*    & Ordered polytomous logistic regression & ordered factor, >2 levels\\ 
 \code{pmm}      & Predictive mean matching & numeric \\ 
\noalign{\vskip 5pt} 
\textit{Other}  \\
 \code{sample} & Random sample from the observed data & any \\
 \code{passive} & Function of other synthesised data & any \\  
\hline 
\end{tabular} \\
 \caption{Built-in synthesising methods. * indicates default parametric methods}\label{tab:meth}
\end{table}

\textit{Controlling the predictions} \\
The synthetic values of the variables are generated sequentially using variables already synthesised and conditional distributions fitted to the same variables in the real data. Next to synthesising model specification, a user may choose the order in which variables should be synthesised (\code{visitSequence} parameter) and also the set of variables to include as predictors in the synthesising model (\code{predictorMatrix} parameter). As mentioned above, the choice of explanatory variables is restricted by the synthesis sequence and variables that are not synthesised yet cannot be used in prediction models. There is a possibility, however, to include as predictors variables that do not belong to the data set to be synthesised.\\

\textit{Handling data with missing or restricted values}\\ 
The aim of producing a synthetic version of a real data here is to mimic their characteristics in all possible ways, which may include missing and restricted values data. Values representing missing data in categorical variables are treated as additional categories and reproducing them is straightforward. Continuous variables with missing data are modelled in two steps. In the first step, we synthesise an auxiliary binary variable specifying whether a value is missing or not. Depending on the method specified by a user for the original variable a logit or CART model is used for synthesis. If there are different types of missing values an auxiliary categorical variable is created to reflect this and an appropriate model is used for synthesis (a polytomous or CART model). In the second step, a synthesising model is fitted to the non-missing values in the original variable and then used to generate synthetic values for the non-missing category records in our auxiliary variable. The auxiliary variable and a variable with non-missing values and zeros for remaining records are used instead of the original variable for prediction of other variables. The missing data codes have to be specified by a user in \code{contNA} parameter of the \code{syn()} function if they differ from the \proglang{R} missing data code \code{NA}.

Restricted values are those where the values for some cases are determined explicitly by those of other variables. In such cases the rules and the corresponding values should be specified using \code{rules} and \code{rvalues} parameters. The variables used in \code{rules} have to be synthesised prior to the variable they refer to. In the synthesis process the restricted values are assigned first and then only the records with not restricted values are synthesised.\\ 

\section{Illustrative examples}
\label{sec:examples}
\subsection{Data}
The \pkg{synthpop} package includes a data frame \code{SD2011} with individual microdata that will be used for illustration. The data set is a subset of survey data collected in 2011 within the Social Diagnosis project (\cite{SD2011}) which aims to investigate objective and subjective quality of life in Poland. The complete data set is freely available at \url{http://www.diagnoza.com/index-en.html} along with a detailed documentation. The \code{SD2011} subset contains 35 selected variables of various type for a sample of 5,000 individuals aged 16 and over.           

\subsection{Simple example}
\label{sec:simex}
To get access to \pkg{synthpop} functions and \code{SD2011} data set we need to load the package via
<<>>=
library(synthpop)
@
For our illustrating examples of \code{syn()} function we use seven variables of various data types which are listed in Table~\ref{tab:vars}.  


\begin{table}[h]
\centering
\begin{tabular}{l l l}
\hline Variable name & Description & Data type  \\ 
\hline \code{sex} & Sex & binary \\ 
 \code{age} & Age & numeric \\ 
 \code{edu} & Highest educational qualification & factor, >2 levels \\ 
 \code{marital} & Marital status  & factor, >2 levels \\ 
 \code{income} & Personal monthly net income  & numeric \\ 
 \code{ls} & Overall life satisfaction & factor, >2 levels \\ 
 \code{wkabint} & Plans to go abroad to work in the next two years & factor, >2 levels \\ 
\hline 
\end{tabular} \\
 \caption{Variables to be synthesised.}\label{tab:vars}
\end{table}


Although function \code{syn()} allows synthesis of a subset of variables (see Section \ref{subsec:extended}), for ease of presentation here we extract variables of interest from \code{SD2011} data set and store them in a data frame called \code{rds} which stands for 'real data set'. The structure of \code{rds} data can be investigated using the \code{head()} function which prints the first rows of a data frame.
<<rds>>=
vars <- c("sex","age","edu","marital","income","ls","wkabint")
rds <- SD2011[,vars]
head(rds)
@

To run a default synthesis only data to be synthesised have to be provided as a function argument. Note that in order to reproduce the results presented below, before running the \code{syn()} function the pseudo random number generator seed has to be fixed
<<>>=
set.seed(17914709)
sds.default <- syn(rds)
@

The resulting object of class \code{synds} called here \code{sds.default}, where \code{sds} stands for 'synthesised data set', is a list. The \code{print} method displays its selected components (see below). An element \code{syn} contains a synthesised data set which can be accessed using a standard list referencing (\code{sds.default$syn}). 

<<>>=
sds.default
@

The remaining (undisplayed) list elements include other \code{syn()} function parameters used in the synthesis. Their names can be listed via \code{names()} function. For a complete description see the \code{syn()} function help page (\code{?syn}).

<<>>=
names(sds.default)
@

By default, all variables except for the first one in the visit sequence (\code{visitSequence}) are synthesised using \code{ctree} implementation of CART models. First variable to be synthesised cannot have predictors that are to be synthesised later on and therefore a random sample (with replacement) is drawn from its observed values. The default visit sequence reflects the order of variables in the real data set - columns are synthesised from left to right. 

The default matrix of predictors (\code{predictorMatrix}) is defined by the visit sequence. All variables that are earlier in the visit sequence are used as predictors. A value of 1 in a predictor matrix means that the column variable is used as a predictor for the target variable in the row. Since the order of variables is exactly the same as in the real data, for the default visit sequence the default predictor matrix has values of 1 in the lower triangle.\\

Synthesising data with default parametric methods is run with the methods listed below. Values of the other \code{syn()} arguments remain the same as for the default synthesis.  

<<results=hide>>=
set.seed(17914709)
sds.parametric <- syn(rds, method = "parametric")
@
<<>>=
sds.parametric$method
@

\subsection{Extended example}
\label{subsec:extended}
To extend the simple example presented in Section~\ref{sec:simex} we change order of synthesis, synthesise only selected variables, customise selection of predictors, handle  missing values in a continuous variable and apply some rules that a variable has to follow.  

\textit{Sequence and scope of synthesis} \\
The default algorithm of synthesising variables in columns from left to right can be changed via the \code{visitSequence} argument. The vector \code{visitSequence} should include indices of columns in an order desired by a user. In addition if we do not want to synthesise some variables we can exclude them from visit sequence. To synthesise variables \code{sex}, \code{age}, \code{ls}, \code{marital} and \code{edu} in this order we run \code{syn()} function with the following specification

<<>>=
set.seed(17914709)
sds.selection <- syn(rds, visitSequence = c(1, 2, 6, 4, 3))
@

An appropriate prediction matrix is created automatically. However, despite the change of visit sequence the variables in \code{predictorMatrix} are arranged as in the original real data. The same refers to \code{method} and synthesised data set \code{syn}.

<<>>=
sds.selection
@

Note that a user-defined \code{method} vector (setting method for each variable separately) and a specified \code{predictorMatrix} both have to include information for all variables present in the original real data set regardless of whether they are in \code{visitSequence} or not. This allows changes in \code{visitSequence} without adjustments to the \code{method} and \code{predictorMatrix}. For variables not to be synthesised but still to be used as a predictor, which needs to be reflected in a \code{predictorMatrix}, an empty \code{method} (\code{""}) should be set.\\  

\textit{Selection of predictors}\\
The most important rule when selecting predictors is that independent variables in a prediction model have to be already synthesised. The only exception is when a variable is used only as a predictor and is not going to be synthesised at all. Assume we want to:
\begin{itemize}
 \item{exclude life satisfaction (\code{ls}) from the predictors of marital status (\code{marital});} 
 \item{use monthly income (\code{income}) as a predictor of life satisfaction (\code{ls}), education (\code{edu}) and marital status (\code{marital}) but do not synthesise income variable itself;}
 \item{use polytomous logistic regression (\code{polyreg}) to generate marital status (\code{marital}) instead of a default \code{ctree} method.}
\end{itemize}

In order to build an adequate predictor matrix, instead of doing it from scratch we can define an initial \code{visitSequence} and corresponding \code{method} vector and run \code{syn()} function with parameter \code{drop.not.used} set to \code{FALSE} (otherwise \code{method} and \code{predictorMatrix} will miss information on  \code{wkabint}), parameter \code{m} indicating number of synthesis set to zero and other arguments left as defaults. Then we can adjust the predictor matrix used in this synthesis and rerun the function with new parameters. The \proglang{R} code for this is given below.

<<results=hide>>=
visitSequence.ini <- c(1, 2, 5, 6, 4, 3)
method.ini <- c("sample", "ctree", "ctree", "polyreg", "", "ctree", "")
set.seed(17914709)
sds.ini <- syn(data = rds, visitSequence = visitSequence.ini,
  method = method.ini, m = 0, drop.not.used = FALSE)
@
<<>>=
sds.ini$predictorMatrix
predictorMatrix.corrected <- sds.ini$predictorMatrix
predictorMatrix.corrected["marital","ls"] <- 0
predictorMatrix.corrected
@
<<results=hide>>=
set.seed(17914709)
sds.corrected <- syn(data = rds, visitSequence = visitSequence.ini,
  method = method.ini, predictorMatrix = predictorMatrix.corrected)
@

\textit{Handling missing values in continuous variables}\\
By default, numeric missing data codes for a continuous variable are treated as non-missing values. This may lead to erroneous synthetic values, especially when standard parametric models are used or when synthetic values are smoothed to decrease disclosure risk. The problem refers not only to the variable in question, but also to variables predicted from it. The parameter \code{contNA} of the \code{syn()} function allows to define missing-data codes for continuous variables in order to model them separately (see Section~\ref{sec:basicfun}). 
In our simple example a continuous variable \code{income} has two types of missing values (\code{NA} and \code{-8}) and the \code{contNA} argument should be defined as follows

<<>>=
contNA.income <- as.list(rep(NA, ncol(rds)))
contNA.income[[5]] <- c(NA,-8)
@ 

\textit{Rules for restricted values}\\
To illustrate application of rules for restricted values consider marital status. According to Polish law males have to be at least 18 to get married. Thus, in our synthesised data set all male individuals younger than 18 should have marital status \code{SINGLE} which is the case in the real data set. Running without rules gives incorrect results, which is particularly problematic for synthesis with parametric methods, where most of the males under 18 are classified as \code{MARRIED} (see summary table below).   

<<>>=
maritalM18.rds <- table(rds[rds$age < 18 & rds$sex == 'MALE' ,"marital"])
maritalM18.default <- table(sds.default$syn[sds.default$syn$age < 18 &
  sds.default$syn$sex == 'MALE',"marital"])
maritalM18.parametric <- table(sds.parametric$syn[sds.default$syn$age < 18 &
  sds.parametric$syn$sex == 'MALE',"marital"])
cbind("Real data" = maritalM18.rds, CART = maritalM18.default,
  Parametric = maritalM18.parametric)
@

Application of a rule, as specified below, leads to the correct results
<<results=hide>>=
rules.marital <- list("","","","age < 18 & sex == 'MALE'","","","")
rvalues.marital <- list(NA,NA,NA,'SINGLE',NA,NA,NA)
set.seed(17914709)
sds.rmarital <- syn(rds, rules = rules.marital, rvalues = rvalues.marital)
set.seed(17914709)
sds.rmarital.param <- syn(rds, rules = rules.marital, 
  rvalues = rvalues.marital, method = "parametric")

rmaritalM18.default <- table(sds.rmarital$syn[sds.rmarital$syn$age < 18
  & sds.rmarital$syn$sex == 'MALE',"marital"])
rmaritalM18.parametric <- table(sds.rmarital.param$syn[
  sds.rmarital.param$syn$age < 18
  & sds.rmarital.param$syn$sex == 'MALE',"marital"])
@
<<>>=
cbind("Real data" = maritalM18.rds, CART = rmaritalM18.default,
  Parametric = rmaritalM18.parametric) 
@


\subsection{Synthetic data analysis}

Optimally an analysis based on the synthesised data should lead to the same statistical inferences as an analysis based on the real data. For illustration we estimate here a simple logistic regression model where our dependant variable is a probability of having intention to work abroad. We use \code{wkabint} variable which specifies the intentions of work migration but we adjust it to disregard the destination country group. Besides we recode current missing data code of variable \code{income} (\code{'-8'}) into \proglang{R} missing data code \code{NA}.

<<>>=
rds$wkabint <- as.character(rds$wkabint)
rds$wkabint[rds$wkabint=='YES, TO EU COUNTRY' |
  rds$wkabint=='YES, TO NON-EU COUNTRY'] <- 'YES'
rds$wkabint <- factor(rds$wkabint) 
rds$income[rds$income==-8] <- NA
@

We generate five synthetic data sets. 
 
<<results=hide>>=
set.seed(17914709)
sds <- syn(rds, m = 5)
@

Before running the models let us compare some descriptive statistics of the real and synthetic data sets. A very useful function in \proglang{R} for this purpose is \code{summary()}. When a data frame is provided as an argument, here our real data set \code{rds}, it produces summary statistics of each variable. 

<<>>=
summary(rds)
@

The \code{summary()} function with the \code{synds} object as an argument gives summary statistics of the variables in the synthesised data set. If more than one synthetic data set has been generated, as default a summary of the first one is displayed. It can be changed using \code{msel} parameter which can be a single number or a vector.

<<>>=                                              
summary(sds)
@
<<results=hide>>=                       
summary(sds, msel = 2)
summary(sds, msel = 1:5)
@                                                

To more easily compare the synthesised variables with the real ones the synthesiser can use a \code{compare.synds()} function. It takes a synthetic data object and a data frame with original data as its arguments and compares relative frequency distributions of each variable in tabular and graphic form. Alternatively it can be used for a subset of variables specified by a \code{vars} argument. For quantitative variables it produces relative frequency distribution of various missing data categories and a histogram of non-missing values. The below function call is followed by an exemplary output for a factor (\code{ls}) and a numeric variable (\code{income}). Note that if a synthetic data object contains multiple synthetic data sets only the first one is used for comparison.

<<results=hide,eval=FALSE>>=  
compare.synds(sds,rds)
@
<<fig=FALSE>>=  
compare.synds(sds,rds,vars="ls")
@

\begin{figure}[!ht]
 \centering
 \includegraphics[width=3.6in]{ls.pdf}
\end{figure}

<<fig=FALSE>>=  
compare.synds(sds,rds,vars="income")  
@

\begin{figure}[!ht]
%\begin{center}
 \begin{minipage}[b]{0.6\linewidth}
  \includegraphics[width=4in]{income.pdf}
 \end{minipage}
 \quad
 \begin{minipage}[b]{0.3\linewidth}
  \includegraphics[width=1.8in]{incomeNA.pdf}
 \end{minipage}
%\end{center}
\end{figure}
We estimate the real data model using generalised linear model implemented in \proglang{R} \code{glm()} function. A \pkg{synthpop} package function \code{glm.synds()} is an equivalent function for estimating models for each of the \code{m} synthesised data sets. A similar function called \code{lm.synds()} is available for a standard linear regression model. Note that the \code{glm.synds()} and \code{lm.synds()} functions have a parameter \code{object} rather than \code{data} as it is the case in \code{glm()} and \code{lm()} functions. An outcome of \code{glm.synds()} and \code{lm.synds()} function is an object of class \code{fit.synds}. If \code{m>1}, printing a \code{fit.synds} object gives estimates for the first synthesised data set only but it can be changed via an \code{msel} argument of a \code{print} method. 
 
<<>>=   
model.rds <- glm(wkabint ~ sex + age + edu + log(income), 
  family = "binomial", data = rds) 
summary(model.rds)
                             
model.sds <- glm.synds(wkabint ~ sex + age + edu + log(income), 
  family = "binomial", object = sds) 
model.sds
@

<<results=hide>>= 
print(model.sds, msel = 3)
@

The \code{summary()} function of a \code{fit.synds} object can be used by the analyst to combine estimates based on all the synthesised data sets. For inference to original data quantities it includes coefficients (\code{beta syn}) and their standard errors (\code{se beta syn}), Z scores (\code{Z syn}) and synthesising errors for coefficients (\code{syn err beta}) and Z-scores (\code{syn err Z}). For inference to population quantities it includes coefficients (\code{est}), synthesising errors (\code{se}) and Z scores (\code{Z}). The mean of the estimates from each of the $m$ synthetic data sets yields unbaised estimates of the coefficients. The variance is estimated differently depending whether inference is made to the real data quantities or the population parameters and whether synthetic data were produced using simple or proper synthesis (for details see \cite{synthpop_RSS}; expressions used to calculate variance for different cases are presented in Table 1). By default a simple synthesis is conducted and inference is made to original data quantities.

<<>>= 
summary(model.sds)
@

Function \code{compare.fit.synds()} allows the synthesiser to compare the estimates based on the synthesised data sets with those based on the real data and presents the results in both tabular and graphical form. 

<<fig=FALSE>>=
compare.fit.synds(model.sds,rds)
@

\begin{figure}[!ht]
 \centering
 \includegraphics[width=5in]{Zcompare.pdf}
\end{figure}


\section{Concluding remarks}
\label{sec:conclusions}

In this paper we presented the basic functionality of \proglang{R} package \pkg{synthpop} for generating synthetic data. Interested readers can consult the package documentation for additional features currently implemented which can be used to influence the disclosure risk and the utility of the synthesised data. Note that \pkg{synthpop} is under continual development and future vesrsions will include, among others, appropriate procedures for synthesising multiple event data, conducting stratified synthesis and generating partially synthetic data. The ultimate aim of \pkg{synthpop} is to provide a comprehensive, flexible and easy to use tool for generating bespoke synthetic data that can be safely released to interested data users. Since there are many different options to synthesise data, developing general guidelines for best practice remains an open issue to be addressed in our future research.


\bibliography{synthpop}
\end{document}
